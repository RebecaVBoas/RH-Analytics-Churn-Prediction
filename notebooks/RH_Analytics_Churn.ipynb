{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. CONFIGURAÇÃO DO AMBIENTE-\n",
        "#Objetivo: import das bibliotecas que serão utilizadas no projeto\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "Lr7zV9HdeQkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7QC8lNPwP3A",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 2. CARGA DE DADOS E LIMPEZA INICIAL (ETL)\n",
        "# Objetivo: Importar o dataset, verificar integridade e remover ruídos.\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Carregamento\n",
        "df = None # Initialize df to None\n",
        "try:\n",
        "    # Corrected file extension from .cvs to .csv\n",
        "    df = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.xls')\n",
        "    print(\"Dataset carregado com sucesso!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Erro: Arquivo não encontrado. Verifique o caminho ou o upload no Colab.\")\n",
        "\n",
        "if df is not None:\n",
        "    # 2. Criação da Variável Alvo Numérica (Auxiliar)\n",
        "    # Mantemos 'Attrition' (Yes/No) para gráficos e criamos 'Attrition_Num' (1/0) para cálculos\n",
        "    if 'Attrition' in df.columns:\n",
        "        df['Attrition_Num'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "    # 3. Limpeza de Colunas Inúteis (Redução de Ruído)\n",
        "    # Elas não ajudam o modelo a diferenciar ninguém, então removemos.\n",
        "    colunas_inuteis = ['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber']\n",
        "    df = df.drop(columns=colunas_inuteis, errors='ignore')\n",
        "\n",
        "    # 4. Verificação de Integridade (Sanity Check)\n",
        "    # Verifica se há linhas duplicadas (remove se houver)\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    print(f\"\\nDimensões Finais do Dataset: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n",
        "\n",
        "    # 5. Validação de Nulos\n",
        "    # Exibe apenas colunas que tenham valores vazios (se nada aparecer, está perfeito)\n",
        "    nulos = df.isnull().sum()\n",
        "    print(\"\\n--- Verificação de Valores Nulos ---\")\n",
        "    print(nulos[nulos > 0] if nulos.sum() > 0 else \"Nenhum valor nulo encontrado.\")\n",
        "\n",
        "    #6. Definição de constantes de visualização dos gŕaficos\n",
        "    # Tema base\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "    #Paleta padrão do projeto\n",
        "    COLOR_NO  = '#2A9D8F'\n",
        "    COLOR_YES = '#E76F51'\n",
        "\n",
        "    # Fonte padrão\n",
        "    plt.rcParams.update({\n",
        "        'figure.figsize': (7, 5),\n",
        "        'axes.titlesize': 14,\n",
        "        'axes.titleweight': 'bold',\n",
        "        'axes.labelsize': 11,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10\n",
        "    })\n",
        "\n",
        "    # Amostra final para garantir que tudo parece certo\n",
        "    df.head()\n",
        "else:\n",
        "    print(\"Não foi possível carregar o dataset, as operações subsequentes foram ignoradas.\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. ANÁLISE EXPLORÁTORIA\n",
        "# Objetivo: Entender quais variáveis influenciam no desligamento dos funcionários\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3.1. ANÁLISE DIMENSIONAL (O Tamanho do Problema)\n",
        "# Objetivo: Entender a proporção de funcionários que saíram (Churn Rate)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Yes: Funcionários que saíram | No: Funcionários ativos\")\n",
        "\n",
        "# Calculando a frequência relativa (%) de cada grupo\n",
        "# normalize=True traz a proporção (0 a 1) e mul(100) converte para porcentagem\n",
        "churn_rate = df['Attrition'].value_counts(normalize=True).mul(100).round(2)\n",
        "\n",
        "# Visualização: Gráfico de Pizza\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "plt.pie(\n",
        "    churn_rate,\n",
        "    labels=churn_rate.index,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=[COLOR_NO, COLOR_YES],\n",
        "    explode=(0.05, 0)     ,\n",
        "    wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
        "    textprops={'fontsize': 11}\n",
        ")\n",
        "\n",
        "\n",
        "plt.title(\n",
        "    'Taxa de Rotatividade de Funcionários (Attrition)',\n",
        "    fontsize=14,\n",
        "    fontweight='bold'\n",
        ")\n",
        "\n",
        "plt.axis('equal')  # Mantém o gráfico redondo\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "32d9-9EWzOTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3.2. ANÁLISE FINANCEIRA (Impacto do Salário)\n",
        "# Objetivo: Verificar se quem ganha menos tende a sair mais\n",
        "# ==============================================================================\n",
        "\n",
        "# Comparação direta das médias salariais\n",
        "print(\"--- Média Salarial por Grupo ---\")\n",
        "print(df.groupby('Attrition')['MonthlyIncome'].mean())\n",
        "\n",
        "# Visualização: Boxplot (Ideal para ver a distribuição e outliers)\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "\n",
        "df.boxplot(\n",
        "    column='MonthlyIncome',\n",
        "    by='Attrition',\n",
        "    ax=ax,\n",
        "    patch_artist=True,\n",
        "    boxprops=dict(facecolor=COLOR_NO, alpha=0.6),\n",
        "    medianprops=dict(color='black', linewidth=2),\n",
        "    whiskerprops=dict(color='gray'),\n",
        "    flierprops=dict(marker='o', markersize=4, alpha=0.5)\n",
        ")\n",
        "\n",
        "ax.set_title('Distribuição Salarial por Situação de Emprego')\n",
        "ax.set_ylabel('Salário Mensal ($)')\n",
        "ax.set_xlabel('')\n",
        "plt.suptitle('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yw9EkQKcPrjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================================\n",
        "# 3.3. ANÁLISE DE VIAGENS (Influência das viagens)\n",
        "#Objetivo: Verificar a relação entre frequência de viagens e o desligamento da empresa\n",
        "# ====================================================================================\n",
        "\n",
        "#Cruzamento das variáveis\n",
        "travel_attrition = pd.crosstab(\n",
        "    df['BusinessTravel'],\n",
        "    df['Attrition'],\n",
        "    normalize='index'\n",
        ")\n",
        "\n",
        "#Visualização: Gráficos de barras empilhadas\n",
        "travel_attrition[['No', 'Yes']].plot(\n",
        "    kind='bar',\n",
        "    stacked=True,\n",
        "    color=[COLOR_NO, COLOR_YES],\n",
        "    edgecolor='white'\n",
        ")\n",
        "\n",
        "plt.title('Proporção de Saída por Frequência de Viagem')\n",
        "plt.ylabel('Proporção')\n",
        "plt.xlabel('Frequência de Viagem')\n",
        "plt.legend(title='Attrition', loc='upper right', bbox_to_anchor=(1.15, 1))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2A6dfH3kQOlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3.4. ANÁLISE DE CORRELAÇÃO (O que influencia a saída?)\n",
        "#Obejtivo: Analisar de forma mais abrange as variáveis\n",
        "# ==============================================================================\n",
        "\n",
        "colunas_analise = ['Attrition_Num', 'Age', 'MonthlyIncome',\n",
        "                   'TotalWorkingYears', 'YearsAtCompany', 'DistanceFromHome']\n",
        "# Cálculo da Matriz\n",
        "correlacao = df[colunas_analise].corr()\n",
        "\n",
        "# Visualização: Heatmap\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "sns.heatmap(\n",
        "    correlacao,\n",
        "    annot=True,\n",
        "    cmap='RdBu_r',\n",
        "    fmt='.2f',\n",
        "    center=0,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={'label': 'Correlação'}\n",
        ")\n",
        "\n",
        "plt.title('Correlação entre Variáveis e Rotatividade')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-GKyaw-fk9o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3.5. ANÁLISE ETÁRIA (Verificar se jovens saem mais)\n",
        "# Obejtivo: Validar analise de hotmap e verificar as categorias etárias que mais\n",
        "# saem da empresa\n",
        "# ==============================================================================\n",
        "\n",
        "# Definindo bins e labels\n",
        "# 18-25: Jovem | 26-35: Adulto | 36-50: Senior | 50+: Veterano\n",
        "\n",
        "bins = [18, 25, 35, 50, float('inf')]\n",
        "labels = ['Jovem', 'Adulto', 'Senior', 'Veterano']\n",
        "\n",
        "# Criando uam nova coluna de categoria\n",
        "df['Categoria_Idade'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Verificando a taxa de sáida por essa categoria\n",
        "churn_idade = pd.crosstab(df['Categoria_Idade'], df['Attrition'], normalize='index') * 100\n",
        "\n",
        "print(\"--- Taxa de Saída por Faixa Etária ---\")\n",
        "print(churn_idade)\n",
        "\n",
        "# Visualização: grafíco de barras empilhadas\n",
        "churn_idade[['No', 'Yes']].plot(\n",
        "    kind='bar',\n",
        "    stacked=True,\n",
        "    color=[COLOR_NO, COLOR_YES],\n",
        "    edgecolor='white'\n",
        ")\n",
        "\n",
        "plt.title('Taxa de Rotatividade por Faixa Etária')\n",
        "plt.ylabel('% de Colaboradores')\n",
        "plt.xlabel('Faixa Etária')\n",
        "plt.legend(title='Attrition', bbox_to_anchor=(1.05, 1))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u5MXBB1hOhXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. PRÉ-PROCESSAMENTO PARA MACHINE LEARNING\n",
        "# Objetivo: Transformar textos em números e colocar tudo na mesma escala (0 a 1)\n",
        "# ==============================================================================\n",
        "\n",
        "# Definição das colunas numéricas que precisam de escala\n",
        "colunas_para_escalar = ['Age', 'MonthlyIncome', 'TotalWorkingYears', 'YearsAtCompany', 'DistanceFromHome']\n",
        "\n",
        "# ENCODING: Transformar categóricas (Texto) em Numéricas\n",
        "# drop_first=True: Remove a primeira opção para evitar redundância (Multicolinearidade)\n",
        "df_final = pd.get_dummies(df, columns=['Department', 'Gender', 'BusinessTravel'], drop_first=True)\n",
        "\n",
        "# SCALING: Colocar números grandes e pequenos na mesma régua\n",
        "# Criando o objeto \"Escalador\"\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Aplicando a transformação APENAS nas colunas numéricas do nosso df_final\n",
        "df_final[colunas_para_escalar] = scaler.fit_transform(df_final[colunas_para_escalar])\n",
        "\n",
        "# Validação (Quality Assurance)\n",
        "print(\"--- Verificação do Pré-Processamento ---\")\n",
        "print(\"1. Colunas Numéricas Escaladas (Ex: Age):\")\n",
        "print(df_final[['Age', 'MonthlyIncome']].head(3))\n",
        "\n",
        "print(\"\\n2. Novas Colunas Criadas (Dummies):\")\n",
        "# Mostra colunas que contêm 'Department' no nome para ver se funcionou\n",
        "cols_dummies = [col for col in df_final.columns if 'Department' in col]\n",
        "print(df_final[cols_dummies].head(3))\n",
        "\n",
        "# Definição das Features para o Modelo\n",
        "colunas_para_modelo = colunas_para_escalar + cols_dummies\n"
      ],
      "metadata": {
        "id": "OzdD9DNRUEb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. PREPARAÇÃO PARA MODELAGEM (Split de Treino e Teste)\n",
        "# Objetivo: Separar os dados para garantir que os modelos sejam comparáveis\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Definição de Variáveis\n",
        "# X = As Perguntas (Features) | y = O Gabarito (Target)\n",
        "X = df_final[colunas_para_modelo]\n",
        "y = df['Attrition_Num']\n",
        "\n",
        "# 2. Divisão (Holdout)\n",
        "# Estratégia: 75% para a IA estudar (Train) e 25% para a prova final (Test)\n",
        "# stratify=y garante que a proporção de \"Sim/Não\" seja igual no treino e no teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "print(\"--- Divisão Concluída ---\")\n",
        "print(f\"Treino: {X_train.shape[0]} funcionários | Teste: {X_test.shape[0]} funcionários\")"
      ],
      "metadata": {
        "id": "rsifPP9UdgYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5.1. MODELO A: REGRESSÃO LOGÍSTICA\n",
        "# Objetivo: Modelo base (Baseline) explicável e simples\n",
        "# ==============================================================================\n",
        "\n",
        "# Treinamento\n",
        "# class_weight='balanced': Dá mais peso para quem sai (ajuda a corrigir o desbalanceamento)\n",
        "model_log = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "model_log.fit(X_train, y_train)\n",
        "\n",
        "# Previsão\n",
        "y_pred_log = model_log.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "print(\"--- Performance: Regressão Logística ---\")\n",
        "acuracia = accuracy_score(y_test, y_pred_log)\n",
        "print(f\"Acurácia: {acuracia:.2%}\")\n",
        "print(\"\\nRelatório Detalhado:\")\n",
        "print(classification_report(y_test, y_pred_log, zero_division=0))\n",
        "\n",
        "# Visualização: Matriz de Confusão\n",
        "# Mostra visualmente onde o modelo acertou e onde errou\n",
        "cm = confusion_matrix(y_test, y_pred_log)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fica (0)', 'Sai (1)'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "disp.plot(cmap='OrRd', ax=ax, values_format='d')\n",
        "plt.title('Matriz de Confusão - Regressão Logística')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "okOBDyyFhDJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5.2. MODELO B: RANDOM FOREST (FLORESTA ALEATÓRIA)\n",
        "# Objetivo: Modelo mais robusto para capturar padrões complexos\n",
        "# ==============================================================================\n",
        "\n",
        "# Treinamento\n",
        "# n_estimators=100: Cria 100 árvores para votar\n",
        "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Previsão\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "print(\"--- Performance: Random Forest ---\")\n",
        "acuracia_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Acurácia: {acuracia_rf:.2%}\")\n",
        "print(\"\\nRelatório Detalhado:\")\n",
        "print(classification_report(y_test, y_pred_rf, zero_division=0))\n",
        "\n",
        "# Visualização: Matriz de Confusão\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=['Fica (0)', 'Sai (1)'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "disp_rf.plot(cmap='Greens', ax=ax, values_format='d') # Mudei para verde para diferenciar\n",
        "plt.title('Matriz de Confusão - Random Forest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xAMuTe63SAG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Extraindo a \"nota\" de importância que o modelo deu para cada coluna\n",
        "importancias = rf_model.feature_importances_\n",
        "\n",
        "# 2. Organizando em uma tabela (DataFrame) para facilitar o gráfico\n",
        "# Usamos X_train.columns para pegar os nomes das colunas na ordem certa\n",
        "df_imp = pd.DataFrame({\n",
        "    'Variavel': X_train.columns,\n",
        "    'Importancia': importancias\n",
        "}).sort_values(by='Importancia', ascending=False) # Ordena do mais importante para o menos\n",
        "\n",
        "# 3. Gerando o Gráfico de Barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=df_imp,\n",
        "    x='Importancia',\n",
        "    y='Variavel',\n",
        "    palette='viridis'\n",
        ")\n",
        "\n",
        "plt.title('Ranking de Fatores: O que mais influencia a saída?')\n",
        "plt.xlabel('Peso da Influência (0 a 1)')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "exEfVjvTTI8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. CONCLUSÃO E SIMULAÇÃO (DEPLOYMENT)\n",
        "# Objetivo: Simular o modelo em ação com um caso real (Storytelling)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# 1. PERFIL DO FUNCIONÁRIO \"JOÃO\" (Cenário de Risco)\n",
        "# Vamos criar um funcionário fictício com características críticas\n",
        "# Nota: Para as colunas de texto (Dummies), precisamos definir manualmente\n",
        "# ------------------------------------------------------------------------------\n",
        "novo_funcionario = {\n",
        "    'Age': 29,                    # Jovem\n",
        "    'MonthlyIncome': 2500,        # Salário Baixo (Fator Crítico!)\n",
        "    'TotalWorkingYears': 4,       # Pouca experiência geral\n",
        "    'YearsAtCompany': 2,          # Pouco tempo de casa\n",
        "    'DistanceFromHome': 25,       # Mora longe\n",
        "    # Colunas Dummies (Binárias: 0 ou 1)\n",
        "    # Supondo que ele é de Vendas (Department_Sales = 1) e Homem (Gender_Male = 1)\n",
        "    'Department_Sales': 1,\n",
        "    'Gender_Male': 1,\n",
        "    'BusinessTravel_Travel_Frequently': 0 # Não viaja muito\n",
        "}\n",
        "\n",
        "# 2. PREPARAÇÃO DOS DADOS (Alinhamento com o Treino)\n",
        "# Criamos um DataFrame vazio com AS MESMAS colunas que o modelo aprendeu (X_train)\n",
        "# Isso evita erro de \"shape mismatch\" (diferença de colunas)\n",
        "df_simulacao = pd.DataFrame(columns=X_train.columns)\n",
        "\n",
        "# Adicionamos os dados do João (o que não for preenchido vira 0 ou NaN)\n",
        "df_simulacao.loc[0] = pd.Series(novo_funcionario)\n",
        "\n",
        "# Preenchemos colunas faltantes com 0 (ex: Department_Research que ele não é)\n",
        "df_simulacao = df_simulacao.fillna(0)\n",
        "\n",
        "# 3. ESCALONAMENTO (O Passo Crucial)\n",
        "# Devemos usar o MESMO \"scaler\" treinado no Bloco 4.\n",
        "# Se usarmos um novo scaler, os números ficarão errados.\n",
        "cols_numericas = ['Age', 'MonthlyIncome', 'TotalWorkingYears', 'YearsAtCompany', 'DistanceFromHome']\n",
        "df_simulacao[cols_numericas] = scaler.transform(df_simulacao[cols_numericas])\n",
        "\n",
        "# 4. PREVISÃO (A Inteligência Artificial)\n",
        "# Usando o Random Forest (rf_model) que costuma ser o melhor\n",
        "previsao = rf_model.predict(df_simulacao)\n",
        "probabilidade = rf_model.predict_proba(df_simulacao)\n",
        "\n",
        "# 5. RESULTADO FINAL (Tradução para Negócios)\n",
        "prob_sair = probabilidade[0][1] # Pega a probabilidade da classe 1 (Sair)\n",
        "\n",
        "print(\"---  Relatório de Previsão de Churn ---\")\n",
        "print(f\"Funcionário: João (29 anos, R$ 2.500, Vendas)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "if prob_sair > 0.5:\n",
        "    status = \"ALTO RISCO DE SAÍDA \"\n",
        "    acao = \"Sugerir revisão salarial ou conversa de carreira urgente.\"\n",
        "else:\n",
        "    status = \"BAIXO RISCO (Retenção Provável) \"\n",
        "    acao = \"Manter monitoramento padrão.\"\n",
        "\n",
        "print(f\"Veredito do Modelo: **{status}**\")\n",
        "print(f\"Probabilidade Calculada: {prob_sair:.2%}\")\n",
        "print(f\"Ação Recomendada: {acao}\")"
      ],
      "metadata": {
        "id": "p0gcPHfEhwNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "INSIGTS\n",
        "\n",
        "*  Os funcionarios que mais viajavam foram os que mais sairam da empresa, isso pode indicar excesso de trabalho como um fator para a solicitação de desligamento da empresa.\n",
        "\n",
        "*  O mapa de calor indica que nenhuma variável apresenta correlação forte com a saída de funcionários (Attrition). As maiores correlações negativas, embora fracas, ocorrem com idade, renda mensal e anos totais de trabalho, sugerindo que funcionários mais jovens, com menor salário e menos experiência tendem levemente a sair mais. A variável DistanceFromHome não apresenta relação significativa com Attrition.”\n",
        "\n",
        "*   Funcionários mais jovens (especialmente abaixo de 30 anos) e com menos tempo de carreira têm uma rotatividade muito maior. Criar programas de retenção específicos para \"Jovens Talentos\" ou Planos de Carreira mais claros para quem está começando, pois é onde a sangria é maior.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AVujQXKwyJdK"
      }
    }
  ]
}